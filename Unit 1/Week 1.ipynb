{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84f96cc7",
   "metadata": {},
   "source": [
    "## Week 1 - Understanding PCA, GMM, KNN, and Bias-Variance Trade-Off"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620167ff",
   "metadata": {},
   "source": [
    "## Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a24d5f",
   "metadata": {},
   "source": [
    "Principal Component Analysis (PCA) is one of the simplest approaches to dimensionality reduction. PCA uses a linear transformation to uncorrelate data while still maintaining the dimensionality of the original data.\n",
    "\n",
    "Essentially, PCA will remove features that are unimportant and will find an underlying linear manifold that the data is embedded in.\n",
    "\n",
    "PCA finds the directions of maximum variance in high-dimensional data and projects it onto a new subspace with equal or fewer dimensions thaan the original\n",
    "\n",
    "There are two approaches on PCA that yield the same result albeit with different processes.\n",
    "   \n",
    "   1. Maximum Variance Formulation\n",
    "   2. Minimum-error Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e43378c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5805d640",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
