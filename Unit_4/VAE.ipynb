{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa9c6594-c455-47b4-8f17-0cc594e51ce2",
   "metadata": {},
   "source": [
    "# Variational Autoencoder\n",
    "Shoutouts:\n",
    "* https://www2.bcs.rochester.edu/sites/jacobslab/cheat_sheet/VariationalAutoEncoder.pdf\n",
    "* https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3ba6c4-3366-411f-9bf3-569624c44350",
   "metadata": {},
   "source": [
    "$z -> x -> p(z|x) -> \\hat{z} -> p(x|\\hat{z}) -> \\hat{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada1bd59-2732-47b0-9148-e9b3f2fb8276",
   "metadata": {},
   "source": [
    "## KL Divergence\n",
    "Motivation: As a distance metric to quantify the difference between two distributions. <br>\n",
    "Key features:\n",
    "* Independent of normalization factor\n",
    "* Independent of scale factors as well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312a4e68-cee7-4c70-bb4f-24a9fbb0da34",
   "metadata": {},
   "source": [
    "## Derivation 1\n",
    "\n",
    "| | D1 | D2 |\n",
    "| --- | --- | --- |\n",
    "|p(a)| .8| .3|\n",
    "|p(b)| .1| .3|\n",
    "|p(c)| .1| .4|\n",
    "\n",
    "Some sequence X **taken from D1**: abcba\n",
    "\n",
    "Ratio to see distribution simmilarity: $\\frac{p(X|D1)}{p(X|D2)}$\n",
    "* closer to one means distributions are closer\n",
    "\n",
    "Probability p(X|D1) = $p_{D1}(a)^{n_a} * p_{D1}(b)^{n_b} * p_{D1}(c)^{n_c}$ <br>\n",
    "Probability p(X|D2) = $p_{D2}(a)^{n_a} * p_{D2}(b)^{n_b} * p_{D2}(c)^{n_c}$\n",
    "\n",
    "Generalization:\n",
    "\n",
    "$$\\frac{p_{D1}(a)^{n_a} * p_{D1}(b)^{n_b} * p_{D1}(c)^{n_c}}{p_{D2}(a)^{n_a} * p_{D2}(b)^{n_b} * p_{D2}(c)^{n_c}}$$\n",
    "\n",
    "Now put a log on it and exponent to normalize for scaling factors and the sequence size:\n",
    "\n",
    "$$log(\\frac{p_{D1}(a)^{n_a} * p_{D1}(b)^{n_b} * p_{D1}(c)^{n_c}}{p_{D2}(a)^{n_a} * p_{D2}(b)^{n_b} * p_{D2}(c)^{n_c}})^{\\frac{1}{n}}$$\n",
    "\n",
    "Now simplify:\n",
    "\n",
    "$$\\frac{n_a}{n}log(p_{D1}(a)) + \\frac{n_b}{n}log(p_{D1}(b)) + \\frac{n_c}{n}log(p_{D1}(c)) - \\frac{n_a}{n}log(p_{D2}(a)) + \\frac{n_b}{n}log(p_{D2}(b)) + \\frac{n_c}{n}log(p_{D2}(c))$$\n",
    "\n",
    "Recall that we are taking our random draw X from  D1, so as N -> big the ratio $\\frac{n_a}{n} -> p_{D1}(a)$<br>\n",
    "**Note:** If we were to assume the random draw X was from D1 then the ration would collapse to $p_{D2}(a)$, instead. This is why KL divergences is **Asymetric**. $D_{KL}(D1 || D2) \\neq D_{KL}(D2 || D1)$\n",
    "\n",
    "$$p_{D1}(a)log(p_{D1}(a)) + p_{D1}(b)log(p_{D1}(b)) + p_{D1}(c)log(p_{D1}(c)) - p_{D1}(a)log(p_{D2}(a)) - p_{D1}(b)log(p_{D2}(b)) - p_{D1}(c)log(p_{D2}(c))$$ <br>\n",
    "\n",
    "re-arrange:\n",
    "\n",
    "$$p_{D1}(a)log(p_{D1}(a)) - p_{D1}(a)log(p_{D2}(a)) + p_{D1}(b)log(p_{D1}(b)) - p_{D1}(b)log(p_{D2}(b)) + p_{D1}(c)log(p_{D1}(c)) - p_{D1}(c)log(p_{D2}(c))$$ <br>\n",
    "\n",
    "Simplify:\n",
    "\n",
    "$$p_{D1}(a)log(\\frac{p_{D1}(a)}{p_{D2}(a)}) +p_{D1}(b)log(\\frac{p_{D1}(b)}{p_{D2}(b)}) + p_{D1}(c)log(\\frac{p_{D1}(c)}{p_{D2}(c)})$$ <br>\n",
    "\n",
    "Generalize for more M classes instead of just 3:\n",
    "\n",
    "$$\\sum_i^m p_{D1}(i)log(\\frac{p_{D1}(i)}{p_{D2}(i)})$$\n",
    "\n",
    "Generalize for Continuous distributions instead of discreet:\n",
    "\n",
    "$$\\int_{-\\infty}^{\\infty} p_{D1}(x)log(\\frac{p_{D1}(x)}{p_{D2}(x)}) dx$$\n",
    "\n",
    "or\n",
    "$$\\int_{x \\~ D1} p_{D1}(x)log(\\frac{p_{D1}(x)}{p_{D2}(x)}) dx$$\n",
    "\n",
    "Equivalent to \n",
    "\n",
    "$$D_{KL} = \\mathbb{E}_{x \\~ D1(x)} [log(\\frac{p_{D1}(x)}{p_{D2}(x)})]$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c646abcd-fb05-469c-8b9c-39eee80311a2",
   "metadata": {},
   "source": [
    "# Take 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c56d5a3-4e81-4707-b1e6-ad0ea623b891",
   "metadata": {},
   "source": [
    "**Motivation:**\n",
    "<br>\n",
    "Our purpose is to learn the generative\n",
    "process, i.e., p(x|z) (we assume p(z) is known). A good p(x|z) would assign high probabilities to\n",
    "observed x; hence, we can learn a good p(x|z) by maximizing the probability of observed data,\n",
    "i.e., p(x). Assuming that p(x|z) is parameterized by Î¸, we need to solve the following optimization\n",
    "problem. Which is to maximize the following:\n",
    "<br>\n",
    "\n",
    "$$p_\\theta(x) = \\int_zp_\\theta(x|z)p(z)dz $$\n",
    "\n",
    "\n",
    "\n",
    "Because that is the probability of $x \\cup z$. In this case, the x is our samples which we have \"drawn\" from the \"imaginary\" distribution z. In other words this is the probability of us getting the data that we have. Since our samples obviously exist, we want $p_\\theta(x)$ to be closer to 1.<br>\n",
    "Unfortunately, taking the integral over $p(x)$ is intractable (aka very computationally expensive) when dealing with high dimmensions.<br>\n",
    "<br>\n",
    "The solution is to actually take a step back and look at a different part of the VAE, and that is the decoder **$p_\\theta(z|x)$**, we can't actually integrate over that though since it is a latent mapping that we don't know. Instead the best we can do is try to apporoximate it with our own version **$q_\\phi(z|x)$**.<br>\n",
    "To do this we use **Variational Inference** with **KL divergence**.Aka, want to minimize the $D_{KL}(q_\\phi(z|x) || p_\\theta(z|x))$\n",
    "$$\n",
    "\\begin{align}\n",
    "D_{KL}(q_\\theta(z|x) || p_\\theta(z|x)) & = \\int_{z}(q_\\phi(z|x)log(\\frac{q_\\phi(z|x)}{p_\\theta(z|x)}dz \\\\\n",
    "& = \\int_{z}(q_\\phi(z|x)log(\\frac{q_\\phi(z|x)p_\\theta(x)}{p_\\theta(z,x)})dz \\\\\n",
    "& = \\int_{z}(q_\\phi(z|x)\\bigg(log\\big(\\frac{q_\\phi(z|x)}{p_\\theta(z,x)}\\big) + log\\big(p_\\theta(x)\\big)\\bigg)dz \\\\\n",
    "& = \\int_{z}(q_\\phi(z|x)\\bigg(log\\big(\\frac{q_\\phi(z|x)}{p_\\theta(z,x)}\\big)\\bigg)dz + \\int_{z}(q_\\phi(z|x)log\\big(p_\\theta(x)\\big)dz \\\\\n",
    "D_{KL}(q_\\theta(z|x) || p_\\theta(z|x)) & = \\int_{z}(q_\\phi(z|x)\\bigg(log\\big(\\frac{q_\\phi(z|x)}{p_\\theta(z,x)}\\big)\\bigg)dz + log\\big(p_\\theta(x)\\big) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "Now use substitution with:\n",
    "$$-\\mathcal{L}(\\phi, \\theta) = \\int_{z}(q_\\phi(z|x)\\bigg(log\\big(\\frac{q_\\phi(z|x)}{p_\\theta(z,x)}\\big)\\bigg)dz$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "D_{KL}(q_\\theta(z|x) || p_\\theta(z|x)) & =  - \\mathcal{L}(\\phi, \\theta) + log\\big(p_\\theta(x)\\big) \\\\\n",
    "D_{KL}(q_\\theta(z|x) || p_\\theta(z|x)) + \\mathcal{L}(\\phi, \\theta) & =  log\\big(p_\\theta(x)\\big) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Since KL Divergence has to be >= 0, we can re-write this as:\n",
    "$$\\mathcal{L}(\\phi, \\theta) <=  log\\big(p_\\theta(x)\\big)$$\n",
    "\n",
    "Reminder that our original objective was to maximize $p_\\theta(x)$. We can do this by maximizing $\\mathcal{L}(\\phi, \\theta)$, which is the lower bound for $p_\\theta(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e20d25-efd9-4292-96d4-1041f11d98c6",
   "metadata": {},
   "source": [
    "### Useful formulas:\n",
    "\n",
    "$$p(a|b) = \\frac{p(b|a)p(a)}{p(b)}$$\n",
    "$$p(a|b)p(b) = p(a,b) = p(b,a) = p(b|a)p(a)$$\n",
    "\n",
    "$$\\mathbb{E}_{x \\~ D1} f() = \\int_xp(x)f()$$\n",
    "\n",
    "$$\\int_{z}(q_\\phi(z|x)f()dz = f()$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed3ba7c-fc1b-470e-b733-4cccfdedff2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
