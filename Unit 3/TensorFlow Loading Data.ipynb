{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "pressing-costa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow.keras as tk\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-national",
   "metadata": {},
   "source": [
    "## Loading Data as a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "worthy-preservation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion_mnist = tk.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "train_images.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "prepared-architect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U tensorflow_datasets # May need this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-retreat",
   "metadata": {},
   "source": [
    "## Using the Dataset API\n",
    "https://www.tensorflow.org/api_docs/python/tf/data/Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "matched-event",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\suman\\tensorflow_datasets\\fashion_mnist\\3.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c8386a1cee4be2921a1a23d468ab76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da3a9f75217a445a8da833983ce72678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa351d9acb4440daa06901f0af386de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling C:\\Users\\suman\\tensorflow_datasets\\fashion_mnist\\3.0.1.incomplete4Z0WAM\\fashion_mnist-train.tfrecord…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling C:\\Users\\suman\\tensorflow_datasets\\fashion_mnist\\3.0.1.incomplete4Z0WAM\\fashion_mnist-test.tfrecord*…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset fashion_mnist downloaded and prepared to C:\\Users\\suman\\tensorflow_datasets\\fashion_mnist\\3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "dataset, metadata = tfds.load('fashion_mnist', as_supervised=True, with_info=True)\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "overall-tours",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class names: ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
     ]
    }
   ],
   "source": [
    "class_names = metadata.features['label'].names\n",
    "print(\"Class names: {}\".format(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "parental-penalty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 60000\n",
      "Number of test examples:     10000\n"
     ]
    }
   ],
   "source": [
    "num_train_examples = metadata.splits['train'].num_examples\n",
    "num_test_examples = metadata.splits['test'].num_examples\n",
    "print(\"Number of training examples: {}\".format(num_train_examples))\n",
    "print(\"Number of test examples:     {}\".format(num_test_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "comic-coast",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(images, labels):\n",
    "  images = tf.cast(images, tf.float32)\n",
    "  images /= 255\n",
    "  return images, labels\n",
    "\n",
    "# The map function applies the normalize function to each element in the train\n",
    "# and test datasets\n",
    "train_dataset =  train_dataset.map(normalize)\n",
    "test_dataset  =  test_dataset.map(normalize)\n",
    "\n",
    "# The first time you use the dataset, the images will be loaded from disk\n",
    "# Caching will keep them in memory, making training faster\n",
    "train_dataset =  train_dataset.cache()\n",
    "test_dataset  =  test_dataset.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-evolution",
   "metadata": {},
   "source": [
    "The following is how to properly use the dataset API to generate a train and test generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "universal-irrigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "train_dataset = train_dataset.cache().repeat().shuffle(num_train_examples).batch(BATCH_SIZE).map(somefunction)\n",
    "test_dataset = test_dataset.cache().batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "wrong-announcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(train_dataset, epochs=5, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-decade",
   "metadata": {},
   "source": [
    "### tf.normalization method\n",
    "\n",
    "Allows the normalization process to be encorporated into being part of the model, allowing the dataset to be untouched. Normalizing is important because even Neural nets will converge faster if the mean of features is near 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-consumer",
   "metadata": {},
   "source": [
    "### Keras.Input objects for Symbolic representation\n",
    "\n",
    "Like the normalization layer, this allows for certain features of the data to be processed by the model itself rather than a seperate prepocessing code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-preliminary",
   "metadata": {},
   "source": [
    "## Need to include all the info contained here:\n",
    "https://www.tensorflow.org/tutorials/load_data/csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-employee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
