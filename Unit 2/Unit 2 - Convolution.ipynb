{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "european-theory",
   "metadata": {},
   "source": [
    "# Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-madison",
   "metadata": {},
   "source": [
    "In the last few years, CNNs have become popular in the areas of image recognition, object detection, segmentation, and many other tasks in the field of computer vision. They are also becoming popular in the field of **natural language processing (NLP)**.\n",
    "\n",
    "The fundamental difference between fully connected layers and convolution layers is the way the weights are connected to each other in the intermediate layers.\n",
    "\n",
    "One of the biggest challenges of using a linear layer or fully connected layers for computer vision is that they lose all spatial information, and the complexity in terms of the number of weights used by fully connected layers is too big. For example, when we represent a $224\\times 224$ color image as a flat array, we would end up with $150 528$-dimensional feature vector ($224 \\times 224 \\times 3$). When the image is flattened, we lose all the spatial information.\n",
    "\n",
    "There is a better way! It consists in replacing the dense, fully-connected affine transformation in our neural network unit with a different linear operation: **convolution**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-conspiracy",
   "metadata": {},
   "source": [
    "### Why would you use a convolution?\n",
    "\n",
    "Convolutions are very common operations. Here are some image processing examples:\n",
    "\n",
    "* **Edge Detection:** can detect edges by convolving with edge masks (e.g., the Sobel edge detectors)\n",
    "\n",
    "$$S_v = \\left[\\begin{array}{ccc}\n",
    "-1 & 0 & 1\\\\\n",
    "-2 & 0 & 2\\\\\n",
    "-1 & 0 & 1\n",
    "\\end{array}\\right]$$\n",
    "\n",
    "$$S_h = \\left[\\begin{array}{ccc}\n",
    "-1 & -2 & -1\\\\\n",
    "0 & 0 & 0\\\\\n",
    "1 & 2 & 1\n",
    "\\end{array}\\right]$$\n",
    "\n",
    "The vertical and horizontal Sobel edge masks.\n",
    "\n",
    "* **Image Smoothing:** can smooth/blur images using a mean filter.\n",
    "\n",
    "* **Unsharp Masking:** can sharpen imagery by subtracting a mean filtered image from the original.\n",
    "\n",
    "* and many more..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-librarian",
   "metadata": {},
   "source": [
    "* So, various convolutions have the ability to enhance and extract features of interest.\n",
    "\n",
    "* The idea behind a convolutional neural network is to learn the features needed to perform classification (or regression) during the learning process for the neural network. This is in contrast with approaches in which you first identify features of importance, extract them in advance, and then train a classifier (e.g., a neural network) on the extracted features.\n",
    "\n",
    "We would like these localized patterns to have an effect on the output no matter their location in the image, i.e. to be **translation-invariant**. \n",
    "\n",
    "To do that, we would need to force the weights in each per-output-pixel family of patterns to have same values, regardless of pixel location. To achieve this goal, we would need to initialize all weight matrices in a family with the same values, and, during back-propagation, average the gradients for all pixel locations and apply that average as the update to all weights in the family.\n",
    "\n",
    "For this reason, CNNs are often called **shared weight neural networks**. This is because several connections in the network are tied together to have the same value.\n",
    "\n",
    "**CNNs can have much fewer parameters than fully connected layers**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-ecuador",
   "metadata": {},
   "source": [
    "Consider a 2-D convolution (used, for example, in image processing):\n",
    "\n",
    "$$g(x,y) \\ast f(x,y) = \\sum_{s=-a}^a \\sum_{t=-b}^b g(s,t) f(x-s, y-t)$$\n",
    "\n",
    "where $g$ is the filter and $f$ is the image to be convolved. Essentially, we flip both horizontally and vertically and, then, slide $g$ accross $f$ where at each location we perform a pointwise multiplication and then a sum.\n",
    "\n",
    "To understand better how are we exactly creating a neural network that extracts features using convolution operations, we need to first consider that a convolutional can be written as a *linear operation* with a **doubly block circulant matrix**.\n",
    "\n",
    "$$H(x,y) = F(x,y) \\ast g(x,y)$$\n",
    "\n",
    "is the same as\n",
    "\n",
    "$$h = Gf$$\n",
    "\n",
    "where $f$ and $h$ are the vectorized forms of $F$ and $G$ is a doubly block circulant matrix.\n",
    "\n",
    "Consider the following small image:\n",
    "\n",
    "$$Im = \\left[\\begin{array}{cccc}\n",
    "1 & 2 & 3 & 4\\\\\n",
    "5 & 6 & 7 & 8\\\\\n",
    "9 & 10 & 11 & 12\\\\\n",
    "13 & 14 & 15 & 16\n",
    "\\end{array}\\right]$$\n",
    "\n",
    "We can vectorize it and obtain:\n",
    "\n",
    "$$I^T = [1,2,3,\\dots, 14,15,16]$$\n",
    "\n",
    "Let's consider the following kernel:\n",
    "\n",
    "$$k = \\left[\\begin{array}{ccc}\n",
    "-1 & -2 & -3\\\\\n",
    "-4 & -5 & -6\\\\\n",
    "-7 & -8 & -9\n",
    "\\end{array}\\right]$$\n",
    "\n",
    "Let $G$ be:\n",
    "\n",
    "$$G = \\left[\\begin{array}{cccccccccccccccc}\n",
    "-1 & -2 & -3 & 0 & -4 & -5 & -6 & 0 & -7 & -8 & -9 & 0 & 0 & 0 & 0 & 0\\\\\n",
    "0 & -1 & -2 & -3 & 0 & -4 & -5 & -6 & 0 & -7 & -8 & -9 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & -1 & -2 & -3 & 0 & -4 & -5 & -6 & 0 & -7 & -8 & -9 & 0\\\\\n",
    "0 & 0 & 0 & 0 & 0 & -1 & -2 & -3 & 0 & -4 & -5 & -6 & 0 & -7 & -8 & -9\\\\\n",
    "\\end{array}\\right]$$\n",
    "\n",
    "So, we can write the convolution as the matrix multiplication:\n",
    "\n",
    "$$GI$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-collectible",
   "metadata": {},
   "source": [
    "### Kernel/Filter Sizes\n",
    "\n",
    "Small kernels, like $3 \\times 3$ or $5 \\times 5$ provide very local information. The problem is that we can not assume all structures in our images are 3 pixels or 5 pixels wide.\n",
    "\n",
    "In order to identify larger objects in an image we will need large convolution kernels. Well, sure, at the limit we could get a\n",
    "$32 \\times 32$ kernel for a $32 \\times 32$ image, but we would converge to the old fully connected, affine transformation and lose all the nice properties of convolution. \n",
    "\n",
    "Another option, which is what is used in convolutional neural networks, is stacking one convolution after the other, and at the same time downsampling the image in-between successive convolutions.\n",
    "\n",
    "So, on one hand, the first set of kernels operates on small neighborhoods on first-order, low-level features, while the second set of kernels effectively operates on wider neighborhoods, producing features that are compositions of the previous features. This is a very powerful mechanism that provides convolutional neural networks with the ability to see into very complex scenes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-civilian",
   "metadata": {},
   "source": [
    "### Pooling Layers & Strides\n",
    "\n",
    "Downsampling could in principle occur in different ways. Scaling an image by a half is the equivalent of taking 4 neighboring pixels in input and producing one pixel in output. How we compute the value of the output based on the values of the input is up to us. We could:\n",
    "\n",
    "* **Average-pooling**: average the four pixels. This was a common approach early on, but has since fallen out of favor somewhat.\n",
    "* **Max-pooling**: take the maximum of the four pixels. This is currently the most commonly used approach, but has a downside of discarding the other 3/4ths of the data.\n",
    "* **Stride**: perform a strided convolution, where only every Nth pixel is calculated. A 3x4 convolution with stride 2 still incorporates input from all pixels from the previous layer. Current literature shows promise for this approach, but it has not yet supplanted maxpool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-labor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
